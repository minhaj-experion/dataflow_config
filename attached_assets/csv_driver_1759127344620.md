## CSV Ingestion

### Description

The `PythonCsvDriver` class is responsible for reading and writing CSV data based on a provided configuration.  
It supports custom delimiter handling, encoding, and various other CSV-related options.  
The class utilizes the `read_data` method for reading CSV files and the `write_data` method for writing DataFrame to a CSV file.

---

### How to Use in YAML Config

The YAML configuration defines various parameters for reading and writing CSV files, including input and output file paths, delimiter settings, encoding, and other configuration.

### YAML Example:

```yaml
 mapping:
  from:
    store:
      type: local
      input_path: <source directory path>

    data_format:
      type: csv
      delimiter: ","  # Specifies the delimiter for CSV files
      encoding: <optional encoding>  # Example: "utf-8"
      encoding_errors: <optional error handling>  # Example: "ignore"
      quotechar: <optional quote character>  # Example: "'"
      comment: <optional comment character>  # Example: "#"
      thousands: <optional thousands separator>  # Example: ","
      decimal: <decimal separator>  # Example: "."
      skip_rows:
        start_row_count: <row number to start from>  # Example: 1
        end_row_count: <row number to end at>  # Example: 2
        start_row_at: <optional value to identify start row>  # Example: "John"
      skipfooter: <number of lines to skip at the end>  # Example: 1
      header: <optional header row index or null if no header>
      use_header_names:
        - <optional column name>  # Example: "name"
        - <optional column name>  # Example: "location"
        - <optional column name>  # Example: "price"
        - <optional column name>  # Example: "rate"
      usecols:
        - <optional column to use>  # Example: "name"
        - <optional column to use>  # Example: "price"
      index_col: <optional index column>  # Example: 1
      dtype: <optional data type specifications>  # Example: "id": str
      skipinitialspace: <true/false>  # Ignore spaces after delimiter
      nrows: <optional number of rows to read>  # Example: 1
      na_values:
        - "-"  
        - "null"
        - "NA"
      keep_default_na: <true/false>  # Keep or drop default NA values
      na_filter: <true/false>  # Detect missing values or not
      skip_blank_lines: <true/false>  # Skip completely blank lines
      parse_dates:
        - <date column>  # Example: "sale_date"
      infer_datetime_format: <true/false>  # Infer datetime formats automatically
      dayfirst: <true/false>  # Treat first value in date as day
      chunksize: <optional chunk size>  # Example: 2

    entity:
      include:
        - <regex pattern to include>  # Example: "*all"
      exclude:
        - <regex pattern to exclude>  # Example: "*temp"

  to:
    store:
      type: local
      output_path: <destination directory path>

    data_format:
      type: csv
      delimiter: ","  # Specifies the delimiter for output CSV files
      na_rep: <optional string for missing data representation>  # Example: "NULL"
      header: <true/false>  # Whether to write headers
      columns:
        - <optional column to write>  # Example: "name"
        - <optional column to write>  # Example: "price"
      mode: "w"  # Write mode, can be "w" for overwrite or "a" for append
      float_format: <optional float format>  # Example: "%.2f"
      encoding: <optional encoding>  # Example: "utf-8"
      errors: <optional error handling>  # Example: "replace"
      chunksize: <optional chunk size>  # Example: 2
      decimal: <optional decimal separator>  # Example: ","
      quotechar: <optional quote character>  # Example: "'"
      file_name: "output_{${entity}$}"  # Dynamic filename using Jinja placeholders


      
   
```

### Read Configuration

| Argument                           | Type     | Mandatory | Default Value            | Description                                                                                         |
|------------------------------------|----------|-----------|--------------------------|-----------------------------------------------------------------------------------------------------|
| `store.type`                       | str      | Yes       | local                    | Type of storage location to read input files from. Supported values: `local` (your computer), `s3` (Amazon cloud storage). |
| `store.input_path`                 | str      | Yes       | -                        | Folder or file path where input files are located. Example: `/data/input/`                         |
| `data_format.type`                 | str      | Yes       | csv                      | Format of input data files. Currently supports only CSV (Comma-Separated Values) files.            |
| `data_format.delimiter`           | list     | No        | - ","                    |  List of characters used to separate columns in the input files. Example:<br>`delimiter:`<br>&nbsp;&nbsp;`- ","`<br>&nbsp;&nbsp;`- ";"`          |
| `data_format.encoding`            | str      | No        | utf-8                    | Character encoding used to read the files. UTF-8 is most common and supports many characters/languages. |
| `data_format.encoding_errors`     | str      | No        | ignore                   | How to handle unreadable characters due to encoding errors. `ignore` skips them silently.          |
| `data_format.thousands`           | str      | No        | ,                        | Character used to separate thousands in numbers. Example: `1,000` uses `,` as the separator.       |
| `data_format.decimal`             | str      | No        | .                        | Character used to represent decimal points in numbers. Example: `3.14` uses `.`                    |
| `data_format.quotechar`           | str      | No        | '                        | Character used to enclose values that contain special characters like commas. Example: `'New York, USA'` |
| `data_format.comment`             | str      | No        | #                        | Lines starting with this character are treated as comments and ignored while reading.              |
| `data_format.skip_rows.start_row_count` | int | No   | -                        | Number of rows to skip from the top before reading data. Useful if the file has extra header info. |
| `data_format.skip_rows.end_row_count`   | int | No   | -                        | Number of rows to skip from the bottom of the file.                                                 |
| `data_format.skip_rows.start_row_at`    | str | No   | -                        | Skip all rows from the top until this value is found. Reading starts after this value is located.  |
| `data_format.skipfooter`      | int | No   | 0                        | Number of lines to skip at the bottom of the file during reading.                                  |
| `data_format.header`              | int/null | No        | 0                        | Row number to use as column headers. Set to `None` if there is no header row in the file.          |
| `data_format.names`               | list     | No        | -                        | List of column names to assign when there is no header in the file.                                |
| `data_format.usecols`             | list     | No        | -                        | Only load specific columns from the file. Provide list of column names or indexes.                 |
| `data_format.index_col`           | int      | No        | -                        | Column number to use as the index (row labels) of the DataFrame.                                   |
| `data_format.dtype`               | dict     | No        | -                        |  Specify data types for one or more columns. Example:<br>`dtype:`<br>&nbsp;&nbsp;`id: str`<br>&nbsp;&nbsp;`age: int`                         |
| `data_format.skipinitialspace`    | bool     | No        | False                    | If `True`, extra spaces after delimiters are ignored while reading.                                |
| `data_format.nrows`               | int      | No        | -                        | Number of rows to read from the file. Useful when testing with a subset of data.                   |
| `data_format.na_values`           | list     | No        | "-", "null", "NA"     | Strings to treat as missing or empty values (NaN).                                                  |
| `data_format.keep_default_na`     | bool     | No        | True                     | Whether to also treat default NA values (like empty strings) as missing data.                      |
| `data_format.na_filter`           | bool     | No        | True                     | Detect missing values in the file automatically.                                                    |
| `data_format.skip_blank_lines`    | bool     | No        | True                     | Skip lines in the file that are completely blank.                                                   |
| `data_format.parse_dates`         | list     | No        | -                        | Columns that should be converted to dates. Example: `-"created_date"`                             |
| `data_format.infer_datetime_format` | bool   | No        | True                     | Try to automatically detect the date format to speed up loading.                                   |
| `data_format.dayfirst`            | bool     | No        | False                    | If set to `True`, treats dates as day-first (`DD/MM/YYYY`) instead of month-first.                 |
| `data_format.chunksize`           | int      | No        | -                        | Read the file in small chunks of given number of rows. Useful for large files.                     |
| `entity.include`                  | list     | Yes       | "*all"                | List of specific files or entities to include in the process. Use `"*all"` to include everything.|


### Write Configuration 

| Argument                    | Type   | Mandatory | Default Value          | Description                                                                                          |
|----------------------------|--------|------------|-------------------------|------------------------------------------------------------------------------------------------------|
| store.type                 | str    | Yes        | local                   | Type of storage to write output files. Example: `local` for saving on disk.                         |
| store.output_path          | str    | Yes        | -                       | Folder or directory path where output files will be saved.                                          |
| data_format.type           | str    | Yes        | csv                     | Output file format. Currently supports only `csv`.                                                  |
| data_format.delimiter      | str    | Yes        | ,                       | Character used to separate columns in the output file. Example: `,` (comma) or `\``.               |
| data_format.na_rep         | str    | No         | NULL                    | String to represent missing or blank values. Example: `NULL`, `NA`, or `-`.                         |
| data_format.header         | bool   | No         | True                    | Whether to write column headers (names) in the output file.                                         |
| data_format.columns        | list   | No         | -                       | List of specific columns to include in the output. Leave blank to include all.                      |
| data_format.mode           | str    | No         | w                       | How to write the file:<br>• `w` = overwrite<br>• `a` = append                                       |
| data_format.float_format   | str    | No         | "%.2f"                  | Format for writing floating point numbers. Example: `"%.2f"` means two decimal places like `3.14`.  |
| data_format.encoding       | str    | No         | ascii                   | Character encoding for writing the file. Use `utf-8` for multilingual text.                         |
| data_format.errors         | str    | No         | replace                 | What to do if a character can't be written due to encoding:<br>• `replace`<br>• `ignore`            |
| data_format.chunksize      | int    | No         | 2                       | Number of rows to write at a time. Useful for very large files.                                     |
| data_format.decimal        | str    | No         | ,                       | Character to use as decimal point. Example: `3,14` uses `,` as the decimal separator.              |
| data_format.quotechar      | str    | No         | '                       | Character used to wrap text fields, especially when values contain commas or spaces.                |
| data_format.file_name      | str    | Yes        | output_{${entity}$}     | Pattern for output file names. `${entity}` is replaced by the entity/file name.                     |




## Functionality

### Ingestion Flow

- **Read CSV**:  
  The pipeline reads the CSV files specified in the `input_path` from the `from` block. It uses the `PythonCsvDriver` to load the file, applying configurations like delimiter, column names, data types, and other processing rules.

- **Process Data**:  
  After loading the data, any necessary transformations are performed according to the configuration.

- **Write CSV**:  
  The processed data is then written to the `output_path` specified in the `to` block. The filename is dynamically generated using Jinja placeholders (e.g., `{${entity}$}`).

---

